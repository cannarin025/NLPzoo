{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/umerhasan17/NLPzoo/blob/master/text-summarisation/keyword_extraction_TextRank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "am6MGHA7bePq"
   },
   "source": [
    "# TextRank\n",
    "\n",
    "TextRank is an algorithm based off of PageRank which is used to extract keywords from bodies of text.\n",
    "\n",
    "Original source code from [Bramble Xu](https://gist.github.com/BrambleXu/3d47bbdbd1ee4e6fc695b0ddb88cbf99#file-textrank4keyword-py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dkl7-KcVbWTI"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "class TextRank4Keyword():\n",
    "    \"\"\"Extract keywords from text\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.d = 0.85 # damping coefficient, usually is .85\n",
    "        self.min_diff = 1e-5 # convergence threshold\n",
    "        self.steps = 10 # iteration steps\n",
    "        self.node_weight = None # save keywords and its weight\n",
    "\n",
    "    # Used to add custom stopwords in addition to ones provided by spacy\n",
    "    def set_stopwords(self, stopwords):  \n",
    "        \"\"\"Set stop words\"\"\"\n",
    "        for word in STOP_WORDS.union(set(stopwords)):\n",
    "            lexeme = nlp.vocab[word]\n",
    "            lexeme.is_stop = True\n",
    "    \n",
    "    \n",
    "    def sentence_segment(self, doc, candidate_pos, lower):\n",
    "        \"\"\"Store those words only in cadidate_pos\"\"\"\n",
    "        sentences = []\n",
    "        for sent in doc.sents:\n",
    "            selected_words = []\n",
    "            for token in sent:\n",
    "                # Store words only with cadidate POS tag\n",
    "                if token.pos_ in candidate_pos and token.is_stop is False:\n",
    "                    if lower is True:\n",
    "                        selected_words.append(token.text.lower())\n",
    "                    else:\n",
    "                        selected_words.append(token.text)\n",
    "            sentences.append(selected_words)\n",
    "        return sentences\n",
    "        \n",
    "    def get_vocab(self, sentences):\n",
    "        \"\"\"Get all tokens\"\"\"\n",
    "        vocab = OrderedDict()\n",
    "        i = 0\n",
    "        for sentence in sentences:\n",
    "            for word in sentence:\n",
    "                if word not in vocab:\n",
    "                    vocab[word] = i\n",
    "                    i += 1\n",
    "        return vocab\n",
    "    \n",
    "    def get_token_pairs(self, window_size, sentences):\n",
    "        \"\"\"Build token_pairs from windows in sentences\"\"\"\n",
    "        token_pairs = list()\n",
    "        for sentence in sentences:\n",
    "            for i, word in enumerate(sentence):\n",
    "                for j in range(i+1, i+window_size):\n",
    "                    if j >= len(sentence):\n",
    "                        break\n",
    "                    pair = (word, sentence[j])\n",
    "                    if pair not in token_pairs:\n",
    "                        token_pairs.append(pair)\n",
    "        return token_pairs\n",
    "        \n",
    "    def symmetrize(self, a):\n",
    "        return a + a.T - np.diag(a.diagonal())\n",
    "    \n",
    "    def get_matrix(self, vocab, token_pairs):\n",
    "        \"\"\"Get normalized matrix\"\"\"\n",
    "        # Build matrix\n",
    "        vocab_size = len(vocab)\n",
    "        g = np.zeros((vocab_size, vocab_size), dtype='float')\n",
    "        for word1, word2 in token_pairs:\n",
    "            i, j = vocab[word1], vocab[word2]\n",
    "            g[i][j] = 1\n",
    "            \n",
    "        # Get Symmeric matrix\n",
    "        g = self.symmetrize(g)\n",
    "        \n",
    "        # Normalize matrix by column\n",
    "        norm = np.sum(g, axis=0)\n",
    "        g_norm = np.divide(g, norm, where=norm!=0) # this is ignore the 0 element in norm\n",
    "        \n",
    "        return g_norm\n",
    "\n",
    "    \n",
    "    def get_keywords(self, number=10):\n",
    "        \"\"\"Print top number keywords\"\"\"\n",
    "        node_weight = OrderedDict(sorted(self.node_weight.items(), key=lambda t: t[1], reverse=True))\n",
    "        for i, (key, value) in enumerate(node_weight.items()):\n",
    "            print(key + ' - ' + str(value))\n",
    "            if i > number:\n",
    "                break\n",
    "        \n",
    "        \n",
    "    def analyze(self, text, \n",
    "                candidate_pos=['NOUN', 'PROPN'], \n",
    "                window_size=4, lower=False, stopwords=list()):\n",
    "        \"\"\"Main function to analyze text\"\"\"\n",
    "        \n",
    "        # Set stop words\n",
    "        self.set_stopwords(stopwords)\n",
    "        \n",
    "        # Pare text by spaCy\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        # Filter sentences\n",
    "        sentences = self.sentence_segment(doc, candidate_pos, lower) # list of list of words\n",
    "        \n",
    "        # Build vocabulary\n",
    "        vocab = self.get_vocab(sentences)\n",
    "        \n",
    "        # Get token_pairs from windows\n",
    "        token_pairs = self.get_token_pairs(window_size, sentences)\n",
    "        \n",
    "        # Get normalized matrix\n",
    "        g = self.get_matrix(vocab, token_pairs)\n",
    "        \n",
    "        # Initionlization for weight(pagerank value)\n",
    "        pr = np.array([1] * len(vocab))\n",
    "        \n",
    "        # Iteration\n",
    "        previous_pr = 0\n",
    "        for epoch in range(self.steps):\n",
    "            pr = (1-self.d) + self.d * np.dot(g, pr)\n",
    "            if abs(previous_pr - sum(pr))  < self.min_diff:\n",
    "                break\n",
    "            else:\n",
    "                previous_pr = sum(pr)\n",
    "\n",
    "        # Get weight for each node\n",
    "        node_weight = dict()\n",
    "        for word, index in vocab.items():\n",
    "            node_weight[word] = pr[index]\n",
    "        \n",
    "        self.node_weight = node_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7q_P38hicvhF"
   },
   "outputs": [],
   "source": [
    "text = '''Christmas was coming. One morning in mid-December, Hogwarts woke to \n",
    "find itself covered in several feet of snow. The lake froze solid and the \n",
    "Weasley twins were punished for bewitching several snowballs so that they \n",
    "followed Quirrell around, bouncing off the back of his turban. The few owls \n",
    "that managed to battle their way through the stormy sky to deliver mail had \n",
    "to be nursed back to health by Hagrid before they could fly off again.\\n\\tNo \n",
    "one could wait for the holidays to start. While the Gryffindor common room \n",
    "and the Great Hall had roaring fires, the drafty corridors had become icy \n",
    "and a bitter wind rattled the windows in the classrooms. Worst of all were \n",
    "Professor Snape\\'s classes down in the dungeons, where their breath rose in \n",
    "a mist before them and they kept as close as possible to their hot cauldrons.\n",
    "\\n\\t\\\"I do feel so sorry,\\\" said Draco Malfoy, one Potions class, \\\"for all \n",
    "those people who have to stay at Hogwarts for Christmas because they\\'re not \n",
    "wanted at home.\\\"\\n\\tHe was looking over at Harry as he spoke. Crabbe and Goyle \n",
    "chuckled. Harry, who was measuring out powdered spine of lionfish, ignored them. \n",
    "Malfoy had been even more unpleasant than usual since the Quidditch match. \n",
    "Disgusted that the Slytherins had lost, he had tried to get everyone laughing \n",
    "at how a wide-mouthed tree frog would be replacing Harry as Seeker next. \n",
    "Then he\\'d realized that nobody found this funny, because they were all so \n",
    "impressed at the way Harry had managed to stay on his bucking broomstick. \n",
    "So Malfoy, jealous and angry, had gone back to taunting Harry about having \n",
    "no proper family.''' \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "xlHr2hKXcgGe",
    "outputId": "fd0503e3-af8a-4ab7-d04f-173b82b2c218"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry - 2.437478174603174\n",
      "Hogwarts - 1.8691013888888888\n",
      "Malfoy - 1.7596680284992785\n",
      "way - 1.5346539862914863\n",
      "dungeons - 1.3187027777777778\n",
      "December - 1.225273611111111\n",
      "people - 1.2223866161616161\n",
      "class - 1.2163657828282828\n",
      "twins - 1.1900458333333335\n",
      "snowballs - 1.1900458333333335\n",
      "fires - 1.1774375\n",
      "corridors - 1.1774375\n"
     ]
    }
   ],
   "source": [
    "tr = TextRank4Keyword()\n",
    "tr.analyze(text, candidate_pos=['NOUN', 'PROPN'], window_size=4, lower=False)\n",
    "tr.get_keywords(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TD3lRuZWc5Bf"
   },
   "outputs": [],
   "source": [
    "way - 1.6203819444444445\n",
    "corridors - 1.3187027777777778\n",
    "drafty - 1.1386916666666667\n",
    "wind - 1.1386916666666667\n",
    "dungeons - 1.0814583333333332\n",
    "breath - 1.0814583333333332\n",
    "mist - 1.0814583333333332\n",
    "class - 1.0814583333333332\n",
    "people - 1.0814583333333332\n",
    "Hogwarts - 1.0814583333333332\n",
    "sky - 1.065815972222222\n",
    "mail - 1.065815972222222"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMmFlMYbfwPKPe+nChQ+ndp",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "keyword-extraction-TextRank.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
